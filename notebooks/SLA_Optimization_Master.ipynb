{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Brief: Support Operations & SLA Optimization\n",
    "**Prepared By**: Senior Data Analyst\n",
    "\n",
    "## 1. The Business Problem\n",
    "Our Support Operations team is facing challenges with inconsistent resolution times and missed SLAs. To address this, we have initiated a comprehensive audit of our ticket data to answer:\n",
    "1. **Where are we failing?** (Descriptive Analytics)\n",
    "2. **Why are we failing?** (Statistical & Root Cause Analysis)\n",
    "3. **How can we fix it?** (Predictive Modeling & Strategic Recommendations)\n",
    "\n",
    "### Core KPIs Audited\n",
    "- **SLA Breach Rate**: Target < 10% for Critical Tickets.\n",
    "- **Resolution Time**: Identifying barriers to speed.\n",
    "- **Financial Risk**: Quantifying the cost of service failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup & Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import chi2_contingency, ttest_ind\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Settings for cleaner output\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "Ingesting the raw ticket logs for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('../data/customer_support_tickets.csv')\n",
    "    print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    # Fallback for different working directories\n",
    "    try:\n",
    "        df = pd.read_csv('customer_support_tickets.csv')\n",
    "        print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: customer_support_tickets.csv not found.\")\n",
    "\n",
    "if 'df' in locals():\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SLA Definition & Business Logic (Canonical)\n",
    "**SINGLE SOURCE OF TRUTH**\n",
    "Here we define exactly what constitutes a \"Breach\" and the financial cost associated with it.\n",
    "Any downstream analysis MUST use `Resolution_Hours` and `Is_SLA_Breach` defined here.\n",
    "\n",
    "**Logic Rules**:\n",
    "1. **Ticket Creation**: Imputed (1-5h before first response) due to missing raw log.\n",
    "2. **Resolution Hours**: `Time Resolved` - `Creation Time`.\n",
    "3. **SLA Targets**: Critical (4h), High (8h), Normal (24h), Low (72h)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CANONICAL SLA LOGIC ENGINE ---\n",
    "\n",
    "# A. Date Conversion\n",
    "df['Time_Resolved'] = pd.to_datetime(df['Time to Resolution'], errors='coerce')\n",
    "df['Time_First_Response'] = pd.to_datetime(df['First Response Time'], errors='coerce')\n",
    "\n",
    "# B. Filter Valid Rows\n",
    "df_sla = df.dropna(subset=['Time_Resolved', 'Time_First_Response']).copy()\n",
    "\n",
    "# C. Impute Creation Date (Simulation of Ground Truth)\n",
    "np.random.seed(42)\n",
    "random_hours = pd.to_timedelta(np.random.randint(1, 6, size=len(df_sla)), unit='h')\n",
    "df_sla['Ticket Creation Date'] = df_sla['Time_First_Response'] - random_hours\n",
    "\n",
    "# D. Calculate Resolution Hours\n",
    "df_sla['Resolution_Hours'] = (df_sla['Time_Resolved'] - df_sla['Ticket Creation Date']).dt.total_seconds() / 3600\n",
    "df_sla = df_sla[df_sla['Resolution_Hours'] > 0].copy() # Filter hygiene\n",
    "\n",
    "# E. Define SLA Targets\n",
    "def get_sla_target(priority):\n",
    "    targets = {'Critical': 4, 'High': 8, 'Normal': 24, 'Low': 72}\n",
    "    return targets.get(priority, 24)\n",
    "\n",
    "df_sla['SLA_Target_Hours'] = df_sla['Ticket Priority'].apply(get_sla_target)\n",
    "\n",
    "# F. Determine Breach Status\n",
    "df_sla['Is_SLA_Breach'] = df_sla['Resolution_Hours'] > df_sla['SLA_Target_Hours']\n",
    "df_sla['Is_SLA_Breach_Numeric'] = df_sla['Is_SLA_Breach'].astype(int)\n",
    "\n",
    "# G. Assign Financial Risk (Cost Logic)\n",
    "def get_breach_cost(row):\n",
    "    if not row['Is_SLA_Breach']: return 0\n",
    "    # Cost = Penalty + Churn Risk Estimate\n",
    "    costs = {'Critical': 500, 'High': 200, 'Normal': 50, 'Low': 10}\n",
    "    return costs.get(row['Ticket Priority'], 0)\n",
    "\n",
    "df_sla['Est_Breach_Cost'] = df_sla.apply(get_breach_cost, axis=1)\n",
    "\n",
    "# Extract Hour for Workload Analyis\n",
    "df_sla['Hour_of_Day'] = df_sla['Ticket Creation Date'].dt.hour\n",
    "\n",
    "print(\"\u2705 SLA Logic & Financial Risk Engine Applied.\")\n",
    "print(f\"Analyzable Dataset: {df_sla.shape[0]} tickets.\")\n",
    "display(df_sla[['Ticket Creation Date', 'Resolution_Hours', 'SLA_Target_Hours', 'Is_SLA_Breach', 'Est_Breach_Cost']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "Preparing the data for Machine Learning. We encode categorical variables and define the feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Features for Prediction\n",
    "features = ['Ticket Priority', 'Ticket Channel', 'Ticket Type', 'Customer Age']\n",
    "target = 'Is_SLA_Breach_Numeric'\n",
    "\n",
    "# Prepare ML Dataset\n",
    "ml_df = df_sla[features + [target]].dropna().copy()\n",
    "\n",
    "# One-Hot Encoding\n",
    "ml_df = pd.get_dummies(ml_df, columns=['Ticket Priority', 'Ticket Channel', 'Ticket Type'], drop_first=True)\n",
    "\n",
    "X = ml_df.drop(columns=[target])\n",
    "y = ml_df[target]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Features Prepared. Training Shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predictive Risk Modeling\n",
    "Using **Random Forest** to predict breaches before they occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PHASE 4: PREDICTIVE RISK MODELING (SLA Breach) ---\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Safety checks (prevents silent failures)\n",
    "required_cols = ['Is_SLA_Breach', 'Ticket Type', 'Ticket Priority', 'Ticket Channel', 'Product Purchased']\n",
    "missing = [c for c in required_cols if c not in df_sla.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns before modeling: {missing}. \"\n",
    "                     \"Run SLA feature engineering first (RPT_hours, SLA_Target_Hours, Is_SLA_Breach).\")\n",
    "\n",
    "# Features available at ticket creation (keep this \u201crealistic\u201d for ops triage)\n",
    "feature_cols = ['Ticket Type', 'Ticket Priority', 'Ticket Channel', 'Product Purchased']\n",
    "X = df_sla[feature_cols].copy()\n",
    "y = df_sla['Is_SLA_Breach'].astype(int)\n",
    "\n",
    "# Train/test split (stratify for imbalance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocess categoricals\n",
    "categorical = feature_cols\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical)]\n",
    ")\n",
    "\n",
    "# Models (baseline + stronger)\n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=2000, class_weight=\"balanced\"),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=400, random_state=42, class_weight=\"balanced_subsample\"\n",
    "    )\n",
    "}\n",
    "\n",
    "results = []\n",
    "fitted = {}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", clf)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    fitted[name] = pipe\n",
    "    \n",
    "    # Probabilities for AUC metrics + thresholding\n",
    "    p = pipe.predict_proba(X_test)[:, 1]\n",
    "    yhat = (p >= 0.5).astype(int)\n",
    "\n",
    "    roc = roc_auc_score(y_test, p)\n",
    "    pr  = average_precision_score(y_test, p)\n",
    "\n",
    "    results.append((name, roc, pr))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(name)\n",
    "    print(\"ROC AUC:\", round(roc, 4))\n",
    "    print(\"PR  AUC:\", round(pr, 4))\n",
    "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, yhat))\n",
    "    print(\"\\nReport:\\n\", classification_report(y_test, yhat, digits=3))\n",
    "\n",
    "display(pd.DataFrame(results, columns=[\"Model\", \"ROC_AUC\", \"PR_AUC\"]).sort_values(\"PR_AUC\", ascending=False))\n",
    "\n",
    "# --- COST-SENSITIVE THRESHOLDING ---\n",
    "print(\"\\n--- FINANCIAL RISK OPTIMIZATION ---\")\n",
    "best_model_name = pd.DataFrame(results, columns=[\"Model\", \"ROC_AUC\", \"PR_AUC\"]).sort_values(\"PR_AUC\", ascending=False).iloc[0]['Model']\n",
    "best_model = fitted[best_model_name]\n",
    "probs = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Use existing Cost Logic from Step 3\n",
    "if \"Est_Breach_Cost\" in df_sla.columns:\n",
    "    test_costs = df_sla.loc[X_test.index, \"Est_Breach_Cost\"].fillna(0).values\n",
    "else:\n",
    "    # Fallback if cost column missing (Safety)\n",
    "    priority = df_sla.loc[X_test.index, \"Ticket Priority\"].astype(str)\n",
    "    test_costs = np.where(priority.isin([\"Critical\", \"High\"]), 50, 10)\n",
    "\n",
    "thresholds = np.linspace(0.05, 0.95, 19)\n",
    "best = None\n",
    "\n",
    "for t in thresholds:\n",
    "    pred = (probs >= t).astype(int)\n",
    "    # Expected loss: FN costs you the breach cost; FP costs you time/effort (set to $2 handling cost)\n",
    "    FN = ((y_test.values == 1) & (pred == 0))\n",
    "    FP = ((y_test.values == 0) & (pred == 1))\n",
    "\n",
    "    expected_loss = (test_costs[FN].sum()) + (FP.sum() * 2)\n",
    "    breach_recall = (pred[y_test.values == 1].mean()) \n",
    "    \n",
    "    row = (t, expected_loss, breach_recall)\n",
    "    if (best is None) or (expected_loss < best[1]):\n",
    "        best = row\n",
    "\n",
    "print(f\"Optimal Risk Threshold={best[0]:.2f}\") \n",
    "print(f\"Minimizes Expected Financial Loss to ${best[1]:,.0f} (vs Default 0.50 Threshold)\")\n",
    "print(f\"Breach Recall at this threshold: {best[2]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Financial Risk Evaluation\n",
    "Quantifying the monetary impact of our SLA failures to justify investment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_risk = df_sla['Est_Breach_Cost'].sum()\n",
    "monthly_risk = total_risk / 3  # Assuming dataset covers ~3 months (adjust based on data)\n",
    "\n",
    "print(f\"Total Estimated Breach Cost (Historical): ${total_risk:,.2f}\")\n",
    "print(f\"Average Monthly Financial Risk: ${monthly_risk:,.2f}\")\n",
    "\n",
    "# Breakdown by Priority\n",
    "risk_breakdown = df_sla.groupby('Ticket Priority')['Est_Breach_Cost'].sum().sort_values(ascending=False)\n",
    "print(\"\\n--- Risk Concentration by Priority ---\")\n",
    "print(risk_breakdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optimization / Simulation\n",
    "Designing the \"Shift Overlap\" strategy to mitigate the 10 PM bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly Risk Heatmap\n",
    "hourly_risk = df_sla.groupby('Hour_of_Day').agg(\n",
    "    Volume=('Ticket ID', 'count'),\n",
    "    Breach_Rate=('Is_SLA_Breach_Numeric', 'mean'),\n",
    "    Total_Cost=('Est_Breach_Cost', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "fig = px.bar(hourly_risk, x='Hour_of_Day', y='Total_Cost', \n",
    "             title='Financial Loss by Hour of Day (Where should we add staff?)',\n",
    "             color='Breach_Rate', color_continuous_scale='Reds')\n",
    "fig.show()\n",
    "\n",
    "# Recommendation Logic\n",
    "peak_loss_hour = hourly_risk.loc[hourly_risk['Total_Cost'].idxmax(), 'Hour_of_Day']\n",
    "print(f\"Recommendation: Deploy 'Overlap Shift' starting at {peak_loss_hour}:00 to mitigate peak financial loss.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Executive Storytelling\n",
    "Summarizing the findings for the Board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- STRATEGIC EXECUTIVE SUMMARY ---\")\n",
    "print(f\"1. FINANCIAL EXPOSURE: We are losing ~${monthly_risk:,.0f}/month due to SLA breaches.\")\n",
    "print(f\"2. CRITICAL FAILURE: {risk_breakdown.index[0]} tickets account for the majority of this cost.\")\n",
    "print(f\"3. OPERATIONAL FIX: Implementing a shift overlap at {peak_loss_hour}:00 will address the highest risk interval.\")\n",
    "print(f\"4. AI PREDICTION: Random Forest model deployed to flag at-risk tickets with {roc_auc_score(y_test, probs):.2f} AUC accuracy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DASHBOARD EXPORT (single source of truth) ---\n",
    "\n",
    "# Ensure we use the SLA-processed dataframe\n",
    "export_df = df_sla.copy()\n",
    "\n",
    "# 1. Ensure Ticket ID exists\n",
    "if \"Ticket ID\" not in export_df.columns:\n",
    "    export_df.insert(0, \"Ticket ID\", range(1, len(export_df) + 1))\n",
    "\n",
    "# 2. create Ticket_Date for trending\n",
    "export_df[\"Ticket_Date\"] = pd.to_datetime(export_df[\"First Response Time\"]).dt.date\n",
    "\n",
    "# 3. Add Predictions if available (Best Effort)\n",
    "if 'best_model' in locals():\n",
    "    # Predict on the full dataset for the dashboard\n",
    "    try:\n",
    "        # Re-encode full dataset using the pipeline\n",
    "        # Note: We need to match the feature set used in training\n",
    "        feature_cols = ['Ticket Type', 'Ticket Priority', 'Ticket Channel', 'Product Purchased']\n",
    "        X_full = export_df[feature_cols]\n",
    "        \n",
    "        # Use the fitted model to predict probability\n",
    "        # The model is a Pipeline, so it handles preprocessing\n",
    "        export_df['Pred_Breach_Prob'] = best_model.predict_proba(X_full)[:, 1]\n",
    "        \n",
    "        # Create Risk Buckets\n",
    "        export_df[\"Risk_Bucket\"] = pd.cut(\n",
    "            export_df[\"Pred_Breach_Prob\"],\n",
    "            bins=[0, 0.3, 0.6, 1.0],\n",
    "            labels=[\"Low Risk\", \"Medium Risk\", \"High Risk\"]\n",
    "        )\n",
    "        print(\"\u2705 Predictive Scores added to Dashboard Export.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f Could not add predictions to full export: {e}\")\n",
    "        export_df[\"Risk_Bucket\"] = \"N/A\"\n",
    "else:\n",
    "    export_df[\"Risk_Bucket\"] = \"N/A\"\n",
    "\n",
    "# 4. Select Columns for Tableau\n",
    "dashboard_cols = [\n",
    "    \"Ticket ID\",\n",
    "    \"Ticket_Date\",\n",
    "    \"Ticket Type\",\n",
    "    \"Ticket Priority\",\n",
    "    \"Ticket Channel\",\n",
    "    \"Product Purchased\",\n",
    "    \"Resolution_Hours\",\n",
    "    \"SLA_Target_Hours\",\n",
    "    \"Is_SLA_Breach\",\n",
    "    \"Est_Breach_Cost\",      # Matches our notebook's logic\n",
    "    \"Pred_Breach_Prob\",\n",
    "    \"Risk_Bucket\"\n",
    "]\n",
    "\n",
    "final_cols = [c for c in dashboard_cols if c in export_df.columns]\n",
    "df_dashboard = export_df[final_cols].copy()\n",
    "\n",
    "# Rename 'Est_Breach_Cost' to 'Breach_Cost' for Tableau cleanliness\n",
    "if \"Est_Breach_Cost\" in df_dashboard.columns:\n",
    "    df_dashboard.rename(columns={\"Est_Breach_Cost\": \"Breach_Cost\"}, inplace=True)\n",
    "\n",
    "# 5. Save\n",
    "out_path = \"../outputs/dashboard/customer_support_sla_dashboard.csv\"\n",
    "os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "df_dashboard.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"\u2705 Exported: {out_path}\")\n",
    "display(df_dashboard.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}