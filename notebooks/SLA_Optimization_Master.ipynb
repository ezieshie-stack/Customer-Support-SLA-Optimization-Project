{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Executive Brief: Support Operations & SLA Optimization\n",
                "**Prepared By**: Senior Data Analyst\n",
                "\n",
                "## 1. The Business Problem\n",
                "Our Support Operations team is facing challenges with inconsistent resolution times and missed SLAs. To address this, we have initiated a comprehensive audit of our ticket data to answer:\n",
                "1. **Where are we failing?** (Descriptive Analytics)\n",
                "2. **Why are we failing?** (Statistical & Root Cause Analysis)\n",
                "3. **How can we fix it?** (Predictive Modeling & Strategic Recommendations)\n",
                "\n",
                "### Core KPIs Audited\n",
                "- **SLA Breach Rate**: Target < 10% for Critical Tickets.\n",
                "- **Resolution Time**: Identifying barriers to speed.\n",
                "- **Financial Risk**: Quantifying the cost of service failures."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup & Imports\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import plotly.express as px\n",
                "import plotly.graph_objects as go\n",
                "from scipy.stats import chi2_contingency, ttest_ind, mannwhitneyu, norm\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, average_precision_score\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.inspection import permutation_importance\n",
                "\n",
                "# Settings for cleaner output\n",
                "pd.set_option('display.max_columns', None)\n",
                "sns.set_style(\"whitegrid\")\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "\n",
                "print(\"Libraries loaded.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Data\n",
                "Ingesting the raw ticket logs for analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the dataset\n",
                "try:\n",
                "    df = pd.read_csv('../data/customer_support_tickets.csv')\n",
                "    print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
                "except FileNotFoundError:\n",
                "    try:\n",
                "        df = pd.read_csv('customer_support_tickets.csv')\n",
                "        print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
                "    except FileNotFoundError:\n",
                "        print(\"Error: customer_support_tickets.csv not found.\")\n",
                "\n",
                "if 'df' in locals():\n",
                "    display(df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. SLA Definition & Business Logic (Canonical)\n",
                "**SINGLE SOURCE OF TRUTH**\n",
                "Here we define exactly what constitutes a \"Breach\" and the financial cost associated with it.\n",
                "Any downstream analysis MUST use `Resolution_Hours` and `Is_SLA_Breach` defined here.\n",
                "\n",
                "**Logic Rules**:\n",
                "1. **Ticket Creation**: Imputed (1-5h before first response) due to missing raw log.\n",
                "2. **Resolution Hours**: `Time Resolved` - `Creation Time`.\n",
                "3. **SLA Targets**: Critical (4h), High (8h), Normal (24h), Low (72h)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- CANONICAL SLA LOGIC ENGINE ---\n",
                "\n",
                "# A. Date Conversion\n",
                "df['Time_Resolved'] = pd.to_datetime(df['Time to Resolution'], errors='coerce')\n",
                "df['Time_First_Response'] = pd.to_datetime(df['First Response Time'], errors='coerce')\n",
                "\n",
                "# B. Filter Valid Rows\n",
                "df_sla = df.dropna(subset=['Time_Resolved', 'Time_First_Response']).copy()\n",
                "\n",
                "# C. Impute Creation Date (Simulation of Ground Truth)\n",
                "np.random.seed(42)\n",
                "random_hours = pd.to_timedelta(np.random.randint(1, 6, size=len(df_sla)), unit='h')\n",
                "df_sla['Ticket Creation Date'] = df_sla['Time_First_Response'] - random_hours\n",
                "\n",
                "# D. Calculate Resolution Hours\n",
                "df_sla['Resolution_Hours'] = (df_sla['Time_Resolved'] - df_sla['Ticket Creation Date']).dt.total_seconds() / 3600\n",
                "df_sla = df_sla[df_sla['Resolution_Hours'] > 0].copy() # Filter hygiene\n",
                "\n",
                "# E. Define SLA Targets\n",
                "def get_sla_target(priority):\n",
                "    targets = {'Critical': 4, 'High': 8, 'Normal': 24, 'Low': 72}\n",
                "    return targets.get(priority, 24)\n",
                "\n",
                "df_sla['SLA_Target_Hours'] = df_sla['Ticket Priority'].apply(get_sla_target)\n",
                "\n",
                "# F. Determine Breach Status\n",
                "df_sla['Is_SLA_Breach'] = df_sla['Resolution_Hours'] > df_sla['SLA_Target_Hours']\n",
                "df_sla['Is_SLA_Breach_Numeric'] = df_sla['Is_SLA_Breach'].astype(int)\n",
                "\n",
                "# G. Assign Financial Risk (Cost Logic)\n",
                "def get_breach_cost(row):\n",
                "    if not row['Is_SLA_Breach']: return 0\n",
                "    # Cost = Penalty + Churn Risk Estimate\n",
                "    costs = {'Critical': 500, 'High': 200, 'Normal': 50, 'Low': 10}\n",
                "    return costs.get(row['Ticket Priority'], 0)\n",
                "\n",
                "df_sla['Est_Breach_Cost'] = df_sla.apply(get_breach_cost, axis=1)\n",
                "df_sla['Breach_Cost'] = df_sla['Est_Breach_Cost'] # Alias for modeling\n",
                "\n",
                "# Extract Hour for Workload Analyis\n",
                "df_sla['Hour_of_Day'] = df_sla['Ticket Creation Date'].dt.hour\n",
                "\n",
                "print(\"✅ SLA Logic & Financial Risk Engine Applied.\")\n",
                "print(f\"Analyzable Dataset: {df_sla.shape[0]} tickets.\")\n",
                "display(df_sla[['Ticket Creation Date', 'Resolution_Hours', 'SLA_Target_Hours', 'Is_SLA_Breach', 'Est_Breach_Cost']].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2A: Descriptive Risk Analytics\n",
                "**Goal**: Identify \"Where are we bleeding?\"\n",
                "Visualizing the operational landscape to pinpoint the bleeding."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(x='Ticket Priority', y='Is_SLA_Breach', data=df_sla, order=['Critical', 'High', 'Normal', 'Low'], ci=None, palette='viridis')\n",
                "plt.title('SLA Breach Rate by Priority')\n",
                "plt.ylabel('Breach Rate')\n",
                "plt.axhline(df_sla['Is_SLA_Breach'].mean(), color='red', linestyle='--', label='Overall Average')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 6))\n",
                "sns.histplot(data=df_sla, x='Resolution_Hours', hue='Ticket Priority', bins=50, kde=True, palette='viridis')\n",
                "plt.title('Distribution of Resolution Time by Priority')\n",
                "plt.xlim(0, 100) # Zoom in for readability, adjust as needed\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2B: Diagnostic Root Cause Analysis\n",
                "**Goal**: Explain \"Why is this happening?\"\n",
                "We investigate Volume vs Risk, Channel Friction, and Product Complexity."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 2B.1 Volume vs Risk Analysis ---\n",
                "diagnostic_volume = (\n",
                "    df_sla.groupby(['Ticket Type', 'Ticket Priority'])\n",
                "      .agg(\n",
                "          Tickets=('Ticket ID', 'count'),\n",
                "          Breach_Rate=('Is_SLA_Breach_Numeric', 'mean'),\n",
                "          Avg_Resolution_Hours=('Resolution_Hours', 'mean'),\n",
                "          Total_Cost=('Est_Breach_Cost', 'sum')\n",
                "      )\n",
                "      .reset_index()\n",
                "      .sort_values('Total_Cost', ascending=False)\n",
                ")\n",
                "\n",
                "print(\"--- Volume vs Risk: Top Drivers ---\")\n",
                "display(diagnostic_volume.head(10))\n",
                "\n",
                "# Interpretation: High Cost usually comes from High Volume * High Breach Rate."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 2B.2 Channel Friction Analysis ---\n",
                "channel_diagnostics = (\n",
                "    df_sla.groupby(['Ticket Channel'])\n",
                "      .agg(\n",
                "          Tickets=('Ticket ID', 'count'),\n",
                "          Breach_Rate=('Is_SLA_Breach_Numeric', 'mean'),\n",
                "          Avg_Resolution=('Resolution_Hours', 'mean'),\n",
                "          Avg_Cost=('Est_Breach_Cost', 'mean')\n",
                "      )\n",
                "      .reset_index()\n",
                "      .sort_values('Breach_Rate', ascending=False)\n",
                ")\n",
                "\n",
                "print(\"--- Channel Friction Analysis ---\")\n",
                "display(channel_diagnostics)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 2B.3 Product Complexity Signal ---\n",
                "product_diagnostics = (\n",
                "    df_sla.groupby(['Product Purchased'])\n",
                "      .agg(\n",
                "          Tickets=('Ticket ID', 'count'),\n",
                "          Breach_Rate=('Is_SLA_Breach_Numeric', 'mean'),\n",
                "          Avg_Resolution=('Resolution_Hours', 'mean'),\n",
                "          Total_Cost=('Est_Breach_Cost', 'sum')\n",
                "      )\n",
                "      .query('Tickets >= 10')\n",
                "      .sort_values('Breach_Rate', ascending=False)\n",
                ")\n",
                "\n",
                "print(\"--- Product Complexity: Top Failure Rates ---\")\n",
                "display(product_diagnostics.head(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 2B.4 Statistical Validation (Chi-Square) ---\n",
                "print(\"--- Chi-Square Test: Priority vs Breach ---\")\n",
                "contingency = pd.crosstab(df_sla['Ticket Priority'], df_sla['Is_SLA_Breach'])\n",
                "chi2, p_value, _, _ = chi2_contingency(contingency)\n",
                "\n",
                "print(f\"Chi-Square Statistic: {chi2:.4f}\")\n",
                "print(f\"P-Value: {p_value:.4e}\")\n",
                "\n",
                "if p_value < 0.05:\n",
                "    print(\"✅ Result: Statistically Significant. Priority influences Breach Rate.\")\n",
                "else:\n",
                "    print(\"❌ Result: Not Significant.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2C: Predictive SLA Breach Modeling\n",
                "**Goal**: Predict \"Which incoming tickets will breach?\" early enough to intervene.\n",
                "**Metric**: Minimize Financial Loss (not just accuracy)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 2C.0 GUARDRAILS: Check Data Integrity ---\n",
                "required_cols = ['Is_SLA_Breach', 'Breach_Cost', 'Ticket Creation Date']\n",
                "missing = [c for c in required_cols if c not in df_sla.columns]\n",
                "if missing:\n",
                "    raise ValueError(f\"Missing columns: {missing}. Run SLA + cost attribution cells BEFORE modeling.\")\n",
                "\n",
                "print(\"✅ Integrity Check Passed: Ready for Modeling\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 2C.1 Feature Engineering (High Fidelity Time Features) ---\n",
                "# Using 'Ticket Creation Date' (Timestamp) for precise Interaction Hour\n",
                "\n",
                "time_col = 'Ticket Creation Date'\n",
                "\n",
                "# Add Feature to MAIN DATASET (so it persists for dashboard export)\n",
                "df_sla['Interaction_Hour'] = df_sla[time_col].dt.hour.fillna(12).astype(int)\n",
                "df_sla['DayOfWeek'] = df_sla[time_col].dt.dayofweek.fillna(2).astype(int)\n",
                "df_sla['Is_Weekend'] = (df_sla['DayOfWeek'] >= 5).astype(int)\n",
                "\n",
                "df_model = df_sla.copy()\n",
                "\n",
                "# Handle Categoricals\n",
                "cat_cols = ['Ticket Type', 'Ticket Priority', 'Ticket Channel', 'Product Purchased']\n",
                "for c in cat_cols:\n",
                "    df_model[c] = df_model[c].fillna('Unknown')\n",
                "\n",
                "# Define Features & Target\n",
                "target = 'Is_SLA_Breach_Numeric'\n",
                "features_cat = cat_cols\n",
                "features_num = ['Interaction_Hour', 'Is_Weekend', 'DayOfWeek']\n",
                "\n",
                "print(f\"Modeling with {len(features_cat) + len(features_num)} Features.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 2C.2 Train/Test Split & Pipeline ---\n",
                "X = df_model[features_cat + features_num].copy()\n",
                "y = df_model[target].astype(int).copy()\n",
                "\n",
                "# Stratified Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "# Preprocessing Pipeline\n",
                "preprocess = ColumnTransformer(\n",
                "    transformers=[\n",
                "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), features_cat),\n",
                "        (\"num\", \"passthrough\", features_num),\n",
                "    ]\n",
                ")\n",
                "\n",
                "# Baseline LR Model\n",
                "model_lr = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
                "\n",
                "pipe_lr = Pipeline(steps=[\n",
                "    (\"prep\", preprocess),\n",
                "    (\"model\", model_lr)\n",
                "])\n",
                "\n",
                "pipe_lr.fit(X_train, y_train)\n",
                "\n",
                "proba_test_lr = pipe_lr.predict_proba(X_test)[:, 1]\n",
                "print(\"Baseline LR ROC AUC:\", roc_auc_score(y_test, proba_test_lr))\n",
                "print(\"Baseline LR PR AUC :\", average_precision_score(y_test, proba_test_lr))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 2C.3 Cost-Based Evaluation (Optimize Threshold) ---\n",
                "# We pick the threshold that minimizes EXPECTED FINANCIAL LOSS\n",
                "\n",
                "cost_series = df_model.loc[X_test.index, 'Breach_Cost'].fillna(0).values\n",
                "\n",
                "def expected_cost_at_threshold(y_true, proba, cost, threshold):\n",
                "    y_pred = (proba >= threshold).astype(int)\n",
                "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
                "    \n",
                "    # Cost Parameters\n",
                "    FP_COST = 2 # Operational cost of false alarm (escalation)\n",
                "    \n",
                "    fn_cost = cost[(y_true == 1) & (y_pred == 0)].sum() # Missed Breach (Expensive)\n",
                "    fp_cost = FP_COST * ((y_true == 0) & (y_pred == 1)).sum() # False Alarm (Cheap)\n",
                "    \n",
                "    total = fn_cost + fp_cost\n",
                "    return total, tn, fp, fn, tp\n",
                "\n",
                "thresholds = np.linspace(0.05, 0.95, 19)\n",
                "results = []\n",
                "for t in thresholds:\n",
                "    total, tn, fp, fn, tp = expected_cost_at_threshold(y_test.values, proba_test_lr, cost_series, t)\n",
                "    results.append((t, total, tn, fp, fn, tp))\n",
                "\n",
                "best_lr = sorted(results, key=lambda x: x[1])[0]\n",
                "print(f\"Best LR Threshold: {best_lr[0]:.2f}\")\n",
                "print(f\"Expected Test Set Cost: ${best_lr[1]:,.0f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 2C.4 Upgrade Model (Random Forest) + Feature Importance ---\n",
                "\n",
                "# Random Forest\n",
                "rf = RandomForestClassifier(\n",
                "    n_estimators=300,\n",
                "    random_state=42,\n",
                "    class_weight=\"balanced_subsample\",\n",
                "    min_samples_leaf=3\n",
                ")\n",
                "\n",
                "pipe_rf = Pipeline(steps=[(\"prep\", preprocess), (\"model\", rf)])\n",
                "pipe_rf.fit(X_train, y_train)\n",
                "\n",
                "proba_test_rf = pipe_rf.predict_proba(X_test)[:, 1]\n",
                "print(\"RF ROC AUC:\", roc_auc_score(y_test, proba_test_rf))\n",
                "\n",
                "# Optimize RF Threshold\n",
                "results_rf = []\n",
                "for t in thresholds:\n",
                "    total, tn, fp, fn, tp = expected_cost_at_threshold(y_test.values, proba_test_rf, cost_series, t)\n",
                "    results_rf.append((t, total, tn, fp, fn, tp))\n",
                "\n",
                "best_rf = sorted(results_rf, key=lambda x: x[1])[0]\n",
                "print(f\"Best RF Threshold: {best_rf[0]:.2f}\")\n",
                "print(f\"Expected Test Set Cost: ${best_rf[1]:,.0f}\")\n",
                "\n",
                "# Feature Importance (Permutation)\n",
                "perm = permutation_importance(pipe_rf, X_test, y_test, n_repeats=5, random_state=42, scoring=\"average_precision\")\n",
                "imp = sorted(zip(X_test.columns, perm.importances_mean), key=lambda x: x[1], reverse=True)\n",
                "\n",
                "print(\"\\n--- Top Risk Drivers (Permutation Importance) ---\")\n",
                "for k, v in imp[:5]:\n",
                "    print(f\"{k:20s} {v:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 2C.5 Export Risk Scores for Dashboard ---\n",
                "# Use Best Model (RF) and Threshold\n",
                "final_model = pipe_rf\n",
                "final_thresh = best_rf[0]\n",
                "\n",
                "# Predict on Full Dataset (for Dashboard)\n",
                "# Note: We reuse the pipeline so preprocessing is consistent\n",
                "df_sla['Predicted_Breach_Prob'] = final_model.predict_proba(df_model[features_cat + features_num])[:, 1]\n",
                "df_sla['Risk_Bucket'] = pd.cut(\n",
                "    df_sla['Predicted_Breach_Prob'],\n",
                "    bins=[0, 0.33, 0.66, 1.0],\n",
                "    labels=['Low Risk', 'Medium Risk', 'High Risk'],\n",
                "    include_lowest=True\n",
                ")\n",
                "\n",
                "print(\"✅ Risk Scores Generated & Attached to Application Data.\")\n",
                "display(df_sla[['Ticket Priority', 'Interaction_Hour', 'Predicted_Breach_Prob', 'Risk_Bucket']].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 3: Optimization & Simulation\n",
                "**Goal**: Answer \"What operational change reduces breaches the most?\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 3A. Scenario-Ready Optimization Table ---\n",
                "opt_df = df_sla.copy()\n",
                "\n",
                "# Baseline metrics\n",
                "baseline = {\n",
                "    \"tickets\": len(opt_df),\n",
                "    \"breach_rate\": opt_df['Is_SLA_Breach'].mean(),\n",
                "    \"total_cost\": opt_df['Est_Breach_Cost'].sum()\n",
                "}\n",
                "print(\"Baseline State:\", baseline)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 3B. Identify High-Risk Segments ---\n",
                "segment = (\n",
                "    opt_df.groupby(['Ticket Priority', 'Ticket Channel'])\n",
                "    .agg(\n",
                "        Tickets=('Is_SLA_Breach', 'size'),\n",
                "        Breach_Rate=('Is_SLA_Breach', 'mean'),\n",
                "        Total_Cost=('Est_Breach_Cost', 'sum'),\n",
                "        Avg_Cost=('Est_Breach_Cost', 'mean')\n",
                "    )\n",
                "    .reset_index()\n",
                "    .sort_values('Total_Cost', ascending=False)\n",
                ")\n",
                "\n",
                "display(segment.head(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 3C. Define Scenario Function ---\n",
                "def simulate_intervention(df_in, segment_filter, reduction_rate=0.20):\n",
                "    \"\"\"\n",
                "    segment_filter: boolean mask on df\n",
                "    reduction_rate: percent reduction in breaches for targeted segment\n",
                "    \"\"\"\n",
                "    df_sim = df_in.copy()\n",
                "    \n",
                "    # baseline breaches in target segment\n",
                "    target_mask = segment_filter\n",
                "    target_breaches = df_sim.loc[target_mask, 'Is_SLA_Breach'].sum()\n",
                "    \n",
                "    # expected breaches avoided\n",
                "    avoided = int(round(target_breaches * reduction_rate))\n",
                "    \n",
                "    # simulate: mark some breaches as \"prevented\"\n",
                "    breach_idx = df_sim.loc[target_mask & (df_sim['Is_SLA_Breach'] == 1)].index\n",
                "    \n",
                "    # only flip as many as we \"avoid\"\n",
                "    if len(breach_idx) > 0:\n",
                "        flip_idx = breach_idx[:avoided]\n",
                "        df_sim.loc[flip_idx, 'Is_SLA_Breach'] = False\n",
                "        df_sim.loc[flip_idx, 'Est_Breach_Cost'] = 0\n",
                "    \n",
                "    results = {\n",
                "        \"breaches_avoided\": avoided,\n",
                "        \"new_breach_rate\": df_sim['Is_SLA_Breach'].mean(),\n",
                "        \"new_total_cost\": df_sim['Est_Breach_Cost'].sum(),\n",
                "        \"cost_saved\": df_in['Est_Breach_Cost'].sum() - df_sim['Est_Breach_Cost'].sum()\n",
                "    }\n",
                "    return results\n",
                "\n",
                "print(\"✅ Simulation Engine Ready.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 3D. Run 3 Key Scenarios ---\n",
                "\n",
                "# Scenario 1: Reduce breaches for Critical + Chat by 20%\n",
                "scenario1 = simulate_intervention(\n",
                "    opt_df,\n",
                "    segment_filter=(opt_df['Ticket Priority'] == 'Critical') & (opt_df['Ticket Channel'] == 'Chat'),\n",
                "    reduction_rate=0.20\n",
                ")\n",
                "\n",
                "# Scenario 2: Reduce breaches for High + Email by 15%\n",
                "scenario2 = simulate_intervention(\n",
                "    opt_df,\n",
                "    segment_filter=(opt_df['Ticket Priority'] == 'High') & (opt_df['Ticket Channel'] == 'Email'),\n",
                "    reduction_rate=0.15\n",
                ")\n",
                "\n",
                "# Scenario 3: Reduce breaches for Top 2 cost segments by 10%\n",
                "top2 = segment.head(2)[['Ticket Priority','Ticket Channel']].values.tolist()\n",
                "\n",
                "mask_top2 = pd.Series([False] * len(opt_df))\n",
                "for p, c in top2:\n",
                "    mask_top2 = mask_top2 | ((opt_df['Ticket Priority'] == p) & (opt_df['Ticket Channel'] == c))\n",
                "\n",
                "scenario3 = simulate_intervention(\n",
                "    opt_df,\n",
                "    segment_filter=mask_top2,\n",
                "    reduction_rate=0.10\n",
                ")\n",
                "\n",
                "print(\"Scenarios Run.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 3E. Scenario Comparison Table ---\n",
                "comparison = pd.DataFrame([\n",
                "    {\"Scenario\": \"Baseline\", **baseline, \"breaches_avoided\": 0, \"cost_saved\": 0},\n",
                "    {\"Scenario\": \"S1: Critical+Chat 20% reduction\", **scenario1},\n",
                "    {\"Scenario\": \"S2: High+Email 15% reduction\", **scenario2},\n",
                "    {\"Scenario\": \"S3: Top2 Segments 10% reduction\", **scenario3},\n",
                "])\n",
                "\n",
                "display(comparison)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- DASHBOARD EXPORT ---\n",
                "# Exports the rigorous data for the Streamlit App\n",
                "\n",
                "print(\"Exporting Dashboard Data...\")\n",
                "export_df = df_sla.copy()\n",
                "\n",
                "# Add ID if missing\n",
                "if \"Ticket ID\" not in export_df.columns:\n",
                "    export_df.insert(0, \"Ticket ID\", range(1, len(export_df) + 1))\n",
                "\n",
                "# Realistic Date Simulation (Jan-Mar 2023)\n",
                "np.random.seed(42)\n",
                "start_date = pd.to_datetime('2023-01-01')\n",
                "end_date = pd.to_datetime('2023-03-31')\n",
                "days_range = (end_date - start_date).days\n",
                "random_days = np.random.randint(0, days_range, size=len(export_df))\n",
                "export_df[\"Ticket_Date\"] = [start_date + pd.Timedelta(days=x) for x in random_days]\n",
                "export_df[\"Ticket_Date\"] = pd.to_datetime(export_df[\"Ticket_Date\"]).dt.date\n",
                "\n",
                "# Use the 'Predicted_Breach_Prob' from 2C.5 if available, else 0\n",
                "if 'Predicted_Breach_Prob' in export_df.columns:\n",
                "    export_df['Pred_Breach_Prob'] = export_df['Predicted_Breach_Prob']\n",
                "else:\n",
                "    export_df['Pred_Breach_Prob'] = 0\n",
                "    export_df['Risk_Bucket'] = 'N/A'\n",
                "\n",
                "export_df.rename(columns={\"Est_Breach_Cost\": \"Breach_Cost\"}, inplace=True)\n",
                "\n",
                "# Select Columns\n",
                "final_cols = ['Ticket ID', 'Ticket_Date', 'Ticket Priority', 'Ticket Channel', \n",
                "              'Ticket Type', 'Product Purchased', 'Resolution_Hours', \n",
                "              'Is_SLA_Breach', 'Breach_Cost', 'Pred_Breach_Prob', 'Risk_Bucket']\n",
                "              \n",
                "df_dashboard = export_df[final_cols].copy()\n",
                "out_path = \"../outputs/dashboard/customer_support_sla_dashboard.csv\"\n",
                "os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
                "df_dashboard.to_csv(out_path, index=False)\n",
                "print(f\"✅ Dashboard CSV Exported.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}