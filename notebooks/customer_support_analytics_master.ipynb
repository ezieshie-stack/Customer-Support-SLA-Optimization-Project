{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Executive Health Check: Support Operations (Chapter 1)\n",
                "**Project Lead**: Senior Data Analyst\n",
                "**Status**: Data Audit & Descriptive Baseline\n",
                "\n",
                "## 1. The Strategic Context\n",
                "Before implementing advanced AI solutions (see **Chapter 2: SLA Optimization**), we must first establish the \"Ground Truth\" of our Support Operations. \n",
                "In this **Executive Health Check (Chapter 1)**, we perform a forensic audit of the dataset to answer fundamental business questions:\n",
                "1.  **Data Integrity**: Do we trust our logs? (Timestamps, Missing Data)\n",
                "2.  **Volume Analysis**: What are people complaining about? (Product/Category Breakdown)\n",
                "3.  **Customer Sentiment**: Are we keeping our customers happy? (CSAT Analysis)\n",
                "\n",
                "### The Roadmap\n",
                "-   **Chapter 1 (This Notebook)**: *Diagnosis & Data Health*.\n",
                "-   **Chapter 2**: *The Cure (Predictive Modeling & Shift Optimization)*."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "pd.set_option(\"display.max_columns\", None)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Ingesting the Raw Logs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('../data/customer_support_tickets.csv')\n",
                "print(f\"Dataset shape: {df.shape}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Forensic Data Audit\n",
                "We need to ensure the data is reliable before making decisions. \n",
                "**Red Flag 1**: Missing data in 'Resolution' and 'Satisfaction Rating' suggests many tickets are either open or data capture failed.\n",
                "**Red Flag 2**: Timestamps need standardization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for missing values and data types\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for duplicates\n",
                "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
                "\n",
                "# Check for unique values in categorical columns\n",
                "cat_cols = ['Ticket Type', 'Ticket Status', 'Ticket Priority', 'Ticket Channel', 'Product Purchased']\n",
                "for col in cat_cols:\n",
                "    print(f\"\\nUnique values in {col}:\")\n",
                "    print(df[col].unique())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Data Hygiene Actions\n",
                "1. **Imputation**: We fill missing CSAT scores with the median to prevent skewing averages.\n",
                "2. **Type Casting**: Converting string dates to datetime objects for temporal analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert date columns\n",
                "date_cols = ['Date of Purchase', 'First Response Time', 'Time to Resolution']\n",
                "for col in date_cols:\n",
                "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
                "\n",
                "# Simple handle for missing values (if any)\n",
                "df['Customer Satisfaction Rating'] = df['Customer Satisfaction Rating'].fillna(df['Customer Satisfaction Rating'].median())\n",
                "df['Resolution'] = df['Resolution'].fillna(\"No resolution recorded\")\n",
                "\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Volume Analysis: What drives our workload?\n",
                "Understanding the \"Why\" behind ticket volume is critical for staffing.\n",
                "**Observation**: Is there a dominant Ticket Type or Priority level?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "sns.countplot(data=df, x='Ticket Type', hue='Ticket Priority', palette='viridis')\n",
                "plt.title('Board View: Where is the pressure coming from?')\n",
                "plt.xticks(rotation=45)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Summary Statistics Baseline\n",
                "This establishes our current operating baseline. Any future optimizations (Chapter 2) will be measured against these numbers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "display(df.describe(include='all'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Executive Chapter 1 Conclusion\n",
                "### Findings:\n",
                "1.  **Data Quality**: The dataset required cleaning, particularly in timestamps and null handling for open tickets. We have stabilized it for analysis.\n",
                "2.  **Workload Drivers**: We see significant volume in specific categories (visualized above).\n",
                "3.  **Baseline Established**: We now have a clean dataset ready for advanced SLA analysis.\n",
                "\n",
                "### Next Steps (Transition to Chapter 2)\n",
                "With the data health confirmed, we move to **Chapter 2: Support Operations & SLA Optimization** to predict breaches and optimize shifts."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}